experiment_group: videosaur
experiment_name: movi_c

globals:
  MODE: tsmm
  NUM_SLOTS: 11 # 11
  SLOT_DIM: 128
  VIT_MODEL: vit_base_patch8_224_dino
  FEAT_DIM: "${config_prop: VIT_PARAMS, ${.VIT_MODEL}, FEAT_DIM}"
  NUM_PATCHES: "${config_prop: VIT_PARAMS, ${.VIT_MODEL}, NUM_PATCHES}"
  NUM_GPUS: 1
  BATCH_SIZE_PER_GPU: 32 # 128
  TOTAL_BATCH_SIZE: "${mul: ${.NUM_GPUS}, ${.BATCH_SIZE_PER_GPU}}"
  BASE_LR: 0.0001
  SIM_TEMP: 0.075 # 0.075
  SIM_WEIGHT: 0.1 # 0.1
  TEMPERATURE: 1.0
  STEP: null
  USED_MULTIPLES: []

trainer:
  max_steps: 400000 # 100000
  log_every_n_steps: 500
  val_check_interval: 4000 # 1000
  gradient_clip_val: 0.05 # 0.05
  accumulate_grad_batches: 4

optimizer:
  name: Adam
  # Scale learning rate by batch size: take base lr once for every 32 samples
  lr: "${eval: 'a / 8 * b', ${globals.TOTAL_BATCH_SIZE}, ${globals.BASE_LR}}"
  lr_scheduler:
    name: cosine_decay_with_exponential_tail
    warmup_steps: 2500 # 2500
    decay_steps: "${eval: 'a / 5', ${trainer.max_steps}}"
    min_scale: 0.25
    exp_decay_rate: 0.5
    transition_start_ratio: 0.9
    transition_length_ratio: 0.1
    # name: exp_decay_with_warmup
    # warmup_steps: 2500
    # decay_steps: "${eval: 'a / 4', ${trainer.max_steps}}" # ${trainer.max_steps}

model:
  input_type: video
  mode: ${globals.MODE}
  visualize: true
  visualize_every_n_steps: 10000
  masks_to_visualize: ['decoder', 'grouping', 'conv']
  losses:
    loss_timesim:
      name: CrossEntropyLoss
      target_key: encoder.vit_block_keys12
      remove_last_n_frames: 1
      pred_dims:
        - 0
        - ${globals.NUM_PATCHES}
      target_transform:
        name: utils.FeatureTimeSimilarity
        softmax: true
        temperature: ${globals.SIM_TEMP}
        threshold: 0.0 
    # loss_tsl:
    #   name: CrossEntropyLoss
  loss_weights:
    # loss_tsl: 100000
    loss_timesim: ${globals.SIM_WEIGHT}

  initializer:
    name: VideoSlotInit # SMMInit
    n_slots: ${globals.NUM_SLOTS}
    dim: ${globals.SLOT_DIM}
    # name: RandomSMMInit
    # n_slots: ${globals.NUM_SLOTS}
    # dim: ${globals.SLOT_DIM}
    # hidden_dim: "${mul: ${globals.SLOT_DIM}, 2}"

  encoder:
    backbone:
      name: TimmExtractorv2
      model: ${globals.VIT_MODEL}
      features:
      - vit_block12
      - vit_block11
      - vit_block10
      - vit_block_keys12
      # - vit_block_keys11
      # - vit_block_keys10
      dim: ${globals.SLOT_DIM}
      drop: true
      mode: hc_video
      proj_type: nonlinear
      frozen: true
      pretrained: true
      last_blocks: 3
      model_kwargs:
        dynamic_img_size: True
    #   name: TimmExtractor
    #   model: ${globals.VIT_MODEL}
    #   features:
    #   - vit_block12
    #   - vit_block_keys12
    #   frozen: true
    #   pretrained: true
    # output_transform:
    #   name: networks.two_layer_mlp
    #   inp_dim: ${globals.FEAT_DIM}
    #   outp_dim: ${globals.SLOT_DIM}
    #   hidden_dim: "${mul: ${globals.FEAT_DIM}, 2}"
    #   layer_norm: true

  grouper:
    # name: SelfAttentionGMM
    # dim: ${globals.SLOT_DIM}
    # # hidden_dim: "${mul: ${globals.SLOT_DIM}, 2}"
    # num_slots: ${globals.NUM_SLOTS}
    # iters: 2 # 3
    # # batch_size: ${globals.BATCH_SIZE_PER_GPU}
    # attn_smooth: 'wnconv' # ['gaussian', 'conv', 'wnconv']
    # attn_smooth_size: 5
    # init_temperature: null
    # temperature: ${globals.TEMPERATURE}
    # final_temperature: null
    # # kl_weight: 0.00004
    # gau_min: 0.1 # 0.1 [2.0]
    # gau_max: 2.0 # 2.0 [2.0]
    # drop_rate: null # null
    # step: ${globals.STEP}
    # decay_steps: null # 100000
    # used_multiples: ${globals.USED_MULTIPLES}
    # use_mlp: false
    name: TemporalGMM
    dim: ${globals.SLOT_DIM}
    # hidden_dim: "${mul: ${globals.SLOT_DIM}, 2}"
    num_slots: ${globals.NUM_SLOTS}
    iters: 2 # 3
    attn_smooth: null # ['gaussian', 'conv', 'wnconv', 'wnconv3d']
    attn_smooth_size: 5
    temperature: ${globals.TEMPERATURE}
    gau_min: 0.1 # 0.1 [2.0]
    gau_max: 2.0 # 2.0 [2.0]
    drop_rate: null # null
    use_mlp: false
    # chunk: 4

  latent_processor:
    first_step_corrector_args:
      n_iters: 3 # 3

  decoder:
    name: SlotMixerDecoder
    inp_dim: ${globals.SLOT_DIM}
    embed_dim: ${globals.SLOT_DIM}
    outp_dim:  ${globals.NUM_PATCHES}
    n_patches: ${globals.NUM_PATCHES}
    final_conv: 'wnconv3d'
    kernel_size: 5
    proj_slots: 
      name: networks.two_layer_mlp
      inp_dim: "${mul: ${globals.SLOT_DIM}, 2}"
      outp_dim: ${globals.SLOT_DIM}
      hidden_dim: "${mul: ${globals.SLOT_DIM}, 4}"
      # layer_norm: true
      dropout: 0.1
    allocator:
      name: TransformerEncoder
      dim: ${globals.SLOT_DIM}
      memory_dim: ${globals.SLOT_DIM}
      n_blocks: 2 # 2
      n_heads: 4
    renderer:
      name: MLP
      inp_dim: ${globals.SLOT_DIM}
      outp_dim: 1024
      hidden_dims: [1024, 1024, 1024]
      final_activation: true
    renderer_dim: 1024
    train_chunk: 4
    val_chunk: 24
    use_layer_norms: true
    pos_embed_mode: add

  predictor:
    name: networks.TransformerEncoder
    dim: "${mul: ${globals.SLOT_DIM}, 2}"
    n_blocks: 1 # 1
    n_heads: 4

val_metrics:
  ari:
    name: VideoARI
    ignore_background: true
    pred_key: decoder_masks_hard
    true_key: segmentations
  image_ari:
    name: ImageARI
    ignore_background: true
    video_input: true
    pred_key: decoder_masks_hard
    true_key: segmentations
  mbo:
    name: VideoIoU
    matching: overlap
    ignore_background: true
    pred_key: decoder_masks_hard
    true_key: segmentations
  image_mbo:
    name: ImageIoU
    matching: overlap
    ignore_background: true
    video_input: true
    pred_key: decoder_masks_hard
    true_key: segmentations
  conv_ari:
    name: VideoARI
    ignore_background: true
    pred_key: conv_masks_hard
    true_key: segmentations
  conv_image_ari:
    name: ImageARI
    ignore_background: true
    video_input: true
    pred_key: conv_masks_hard
    true_key: segmentations
  conv_mbo:
    name: VideoIoU
    matching: overlap
    ignore_background: true
    pred_key: conv_masks_hard
    true_key: segmentations
  conv_image_mbo:
    name: ImageIoU
    matching: overlap
    ignore_background: true
    video_input: true
    pred_key: conv_masks_hard
    true_key: segmentations
  slots_ari:
    name: VideoARI
    ignore_background: true
    pred_key: grouping_masks_hard
    true_key: segmentations
  slots_image_ari:
    name: ImageARI
    ignore_background: true
    video_input: true
    pred_key: grouping_masks_hard
    true_key: segmentations
  slots_mbo:
    name: VideoIoU
    matching: overlap
    ignore_background: true
    pred_key: grouping_masks_hard
    true_key: segmentations
  slots_image_mbo:
    name: ImageIoU
    matching: overlap
    ignore_background: true
    video_input: true
    pred_key: grouping_masks_hard
    true_key: segmentations

dataset:
  train_shards: "movi_c/movi_c-train-{000000..000304}.tar"
  val_shards: "movi_c/movi_c-validation-{000000..000007}.tar"
  batch_size: ${globals.BATCH_SIZE_PER_GPU}
  val_batch_size: 8
  val_size: 250
  num_workers: 8
  num_val_workers: 8
  train_pipeline:
    video_size: 24
    chunk_size: 4
    sample_one_chunk_per_video: true
    keys: [video]
    shuffle_size: 512
    transforms:
      name: movi_train
      type: video
      input_size: 224
      h_flip_prob: 0.5
  val_pipeline:
    use_chunks: false
    keys: [video, segmentations]
    transforms:
      name: movi_val
      type: video
      input_size: 224
      num_classes: 11
